#!/usr/bin/env python3
"""
–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π –∏–∑ 1C:–¶–õ (OData) –ø—Ä—è–º–æ –≤ cons.cons_redate.

–ò—Å—Ç–æ—á–Ω–∏–∫: InformationRegister_–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è–ü–µ—Ä–µ–Ω–æ—Å–∞–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏
–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- –ø–æ –æ–¥–Ω–æ–π –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤
- –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç –≤–µ–¥–µ—Ç—Å—è –ø–æ –¥–∞—Ç–µ Period (—á–µ—Ä–µ–∑ sys.sync_state)
- –ø—Ä–∏ –ø–æ—è–≤–ª–µ–Ω–∏–∏ –Ω–æ–≤–æ–π –∑–∞–ø–∏—Å–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª—è redate / redate_time –≤ cons.cons
- –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –ø–µ—Ä–µ–Ω–æ—Å–∞—Ö –≤ Chatwoot
- —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–∞—Ç—ã –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –æ–±—Ä–∞—Ç–Ω–æ –≤ 1C:–¶–õ
"""
from __future__ import annotations

import os
import sys
import asyncio
import logging
import time
from datetime import datetime, timezone, timedelta
from typing import Optional, Dict, Any, List, Set
from urllib.parse import quote

import requests
import asyncpg
from sqlalchemy import select, text, update
from sqlalchemy.dialects.postgresql import insert
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from sqlalchemy.exc import OperationalError

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", ".."))

from FastAPI.config import settings
from FastAPI.models import ConsRedate, Consultation, User
from FastAPI.services.chatwoot_client import ChatwootClient
from FastAPI.services.onec_client import OneCClient
from FastAPI.utils.etl_logging import ETLLogger

LOG_LEVEL = os.getenv("ETL_LOG_LEVEL", "INFO")
INITIAL_FROM_DATE = os.getenv("ETL_REDATE_INITIAL_FROM", "2025-12-01")
PAGE_SIZE = int(os.getenv("ODATA_PAGE_SIZE", "1000"))
MAX_ERROR_LOGS = int(os.getenv("ETL_MAX_ERROR_LOGS", "5"))

ENTITY = "InformationRegister_–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è–ü–µ—Ä–µ–Ω–æ—Å–∞–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏"

logging.basicConfig(level=LOG_LEVEL, format="%(asctime)s %(levelname)s %(message)s")
logger = logging.getLogger("pull_cons_redate")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ OData
ODATA_BASEURL = settings.ODATA_BASEURL_CL or os.getenv("ODATA_BASEURL_CL")
ODATA_USER = settings.ODATA_USER
ODATA_PASSWORD = settings.ODATA_PASSWORD

# Database URL
DATABASE_URL = (
    f"postgresql+asyncpg://{settings.DB_USER}:{settings.DB_PASS}"
    f"@{settings.DB_HOST}:{settings.DB_PORT}/{settings.DB_NAME}"
)

HEADERS = {
    "User-Agent": "cons-middleware/redate-loader",
    "Accept": "application/json",
}


def clean_uuid(value: Optional[str]) -> Optional[str]:
    if not value or value == "00000000-0000-0000-0000-000000000000":
        return None
    return value


def clean_datetime(value: Optional[str]) -> Optional[datetime]:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É –≤ datetime —Å timezone (offset-aware)"""
    if not value or value.startswith("0001-01-01"):
        return None
    try:
        dt = datetime.fromisoformat(value.replace("Z", "+00:00"))
        # –í–ê–ñ–ù–û: –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ datetime –∏–º–µ–µ—Ç timezone (offset-aware)
        if dt.tzinfo is None:
            dt = dt.replace(tzinfo=timezone.utc)
        return dt
    except Exception:
        logger.warning("Failed to parse datetime: %s", value)
        return None


def http_get_with_backoff(url: str, auth: tuple, max_retries: int = 6, timeout: int = 120) -> requests.Response:
    session = requests.Session()
    attempt = 0
    while True:
        try:
            resp = session.get(url, auth=auth, headers=HEADERS, timeout=timeout)
            if resp.status_code in (429, 502, 503, 504):
                if attempt >= max_retries:
                    resp.raise_for_status()
                wait = min(2 ** attempt, 60)
                logger.warning("HTTP %s ‚Äî retry in %s sec (attempt=%s)", resp.status_code, wait, attempt + 1)
                time.sleep(wait)
                attempt += 1
                continue
            resp.raise_for_status()
            return resp
        except requests.RequestException as exc:
            if attempt >= max_retries:
                logger.error("HTTP error after %s attempts: %s", attempt + 1, exc)
                raise
            wait = min(2 ** attempt, 60)
            logger.warning("Request failed: %s ‚Äî retry in %s sec (attempt=%s)", exc, wait, attempt + 1)
            time.sleep(wait)
            attempt += 1


async def get_last_sync_date(db: AsyncSession) -> Optional[datetime]:
    """–ü–æ–ª—É—á–∏—Ç—å –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏, —É–±–µ–¥–∏–≤—à–∏—Å—å —á—Ç–æ –æ–Ω–∞ offset-aware"""
    result = await db.execute(
        text("SELECT last_synced_at FROM sys.sync_state WHERE entity_name = :entity"),
        {"entity": ENTITY},
    )
    row = result.first()
    if row and row[0]:
        dt = row[0]
        # –í–ê–ñ–ù–û: –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ datetime –∏–º–µ–µ—Ç timezone (offset-aware)
        if isinstance(dt, datetime) and dt.tzinfo is None:
            dt = dt.replace(tzinfo=timezone.utc)
        return dt
    return None


async def save_sync_date(db: AsyncSession, value: datetime):
    await db.execute(
        text(
            """
            INSERT INTO sys.sync_state (entity_name, last_synced_at)
            VALUES (:entity, :date)
            ON CONFLICT (entity_name) DO UPDATE SET last_synced_at = EXCLUDED.last_synced_at
            """
        ),
        {"entity": ENTITY, "date": value},
    )


async def ensure_support_objects():
    """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∏–Ω–¥–µ–∫—Å—ã/—Ç–∞–±–ª–∏—Ü—ã –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π."""
    engine = create_async_engine(
        DATABASE_URL,
        echo=False,
        pool_size=1,
        max_overflow=1,
        pool_pre_ping=True
    )
    async with engine.begin() as conn:
        # sync_state —É–∂–µ —Å–æ–∑–¥–∞–µ—Ç—Å—è –≤ init_db, –Ω–æ –ø—Ä–æ–¥—É–±–ª–∏—Ä—É–µ–º –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
        await conn.execute(
            text(
                """
                CREATE TABLE IF NOT EXISTS sys.sync_state (
                    entity_name TEXT PRIMARY KEY,
                    last_synced_at TIMESTAMPTZ
                )
                """
            )
        )
        await conn.execute(
            text(
                """
                CREATE UNIQUE INDEX IF NOT EXISTS uq_cons_redate_keys
                ON cons.cons_redate (cons_key, clients_key, manager_key, period)
                """
            )
        )
    await engine.dispose()


async def upsert_redate_rows(db: AsyncSession, rows: List[Dict[str, Any]]) -> Set[tuple]:
    """–í—Å—Ç–∞–≤–ª—è–µ—Ç –∑–∞–ø–∏—Å–∏ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ –∫–ª—é—á–µ–π –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π"""
    if not rows:
        return set()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ –∑–∞–ø–∏—Å–∏ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
    existing_keys = set()
    for row in rows:
        result = await db.execute(
            select(ConsRedate).where(
                ConsRedate.cons_key == row["cons_key"],
                ConsRedate.clients_key == row["clients_key"],
                ConsRedate.manager_key == row["manager_key"],
                ConsRedate.period == row["period"]
            ).limit(1)
        )
        if result.scalar_one_or_none():
            existing_keys.add((row["cons_key"], row["clients_key"], row["manager_key"], row["period"]))
    
    # –í—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏
    new_rows = [row for row in rows if (row["cons_key"], row["clients_key"], row["manager_key"], row["period"]) not in existing_keys]
    if new_rows:
        stmt = insert(ConsRedate).values(new_rows)
        stmt = stmt.on_conflict_do_nothing(constraint="uq_cons_redate_keys")
        await db.execute(stmt)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–ª—é—á–∏ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
    return {(row["cons_key"], row["clients_key"], row["manager_key"], row["period"]) for row in new_rows}


async def update_consultation_schedule(
    db: AsyncSession,
    cons_key: str,
    new_date: Optional[datetime],
):
    if not new_date or not cons_key:
        return
    await db.execute(
        update(Consultation)
        .where(Consultation.cl_ref_key == cons_key)
        .values(
            redate=new_date.date(),
            redate_time=new_date.time(),
            updated_at=datetime.now(timezone.utc),
        )
    )


async def notify_chatwoot_redate(
    cons_id: str,
    old_date: Optional[datetime],
    new_date: Optional[datetime],
    manager_key: Optional[str] = None,
    db: Optional[AsyncSession] = None,
):
    """
    –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –ø–µ—Ä–µ–Ω–æ—Å–µ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –≤ Chatwoot (–∫–∞–∫ note).
    
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–µ –±—ã–ª–æ –ª–∏ —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Ç–∞–∫–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è.
    """
    if not cons_id or cons_id.startswith(("temp_", "cl_")):
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ ID
        return
    
    if not new_date:
        return
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —É—Ç–∏–ª–∏—Ç—É –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
    from ..utils.notification_helpers import check_and_log_notification
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –±—ã–ª–æ –ª–∏ —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Ç–∞–∫–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
    if db:
        # –í–ê–ñ–ù–û: –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º manager_key –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ —Ö–µ—à–∞ (None -> "")
        # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–Ω—ã–µ —Ö–µ—à–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ –ø–µ—Ä–µ–Ω–æ—Å–∞
        normalized_manager_key = manager_key if manager_key else ""
        notification_data = {
            "old_date": old_date.isoformat() if old_date else None,
            "new_date": new_date.isoformat(),
            "manager_key": normalized_manager_key  # –í—Å–µ–≥–¥–∞ —Å—Ç—Ä–æ–∫–∞, –Ω–µ None
        }
        # –í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–¥–µ–ª—å–Ω—É—é —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è NotificationLog,
        # —á—Ç–æ–±—ã –∑–∞–ø–∏—Å—å –Ω–µ –ø–æ—Ç–µ—Ä—è–ª–∞—Å—å –ø—Ä–∏ rollback –æ—Å–Ω–æ–≤–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ ETL
        already_sent = await check_and_log_notification(
            db=db,
            notification_type="redate",
            entity_id=cons_id,
            data=notification_data,
            use_separate_transaction=True  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–¥–µ–ª—å–Ω—É—é —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
        )
        if already_sent:
            logger.debug(f"Redate notification already sent for cons_id={cons_id}, skipping")
            return
    
    try:
        chatwoot_client = ChatwootClient()
        
        # –ü–æ–ª—É—á–∞–µ–º –§–ò–û –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∏–∑ –ë–î
        manager_name = None
        if manager_key and db:
            try:
                manager_result = await db.execute(
                    select(User.description)
                    .where(User.cl_ref_key == manager_key)
                    .where(User.deletion_mark == False)
                    .limit(1)
                )
                manager_name = manager_result.scalar_one_or_none()
            except Exception as e:
                logger.warning(f"Failed to get manager name for {manager_key}: {e}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –ø–µ—Ä–µ–Ω–æ—Å–µ
        old_date_str = old_date.strftime("%d.%m.%Y %H:%M") if old_date else "–Ω–µ —É–∫–∞–∑–∞–Ω–∞"
        new_date_str = new_date.strftime("%d.%m.%Y %H:%M")
        
        message = f"üìÖ –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–∞\n"
        message += f"–°—Ç–∞—Ä–∞—è –¥–∞—Ç–∞: {old_date_str}\n"
        message += f"–ù–æ–≤–∞—è –¥–∞—Ç–∞: {new_date_str}"
        if manager_name:
            message += f"\n–ú–µ–Ω–µ–¥–∂–µ—Ä: {manager_name}"
        elif manager_key:
            # Fallback –Ω–∞ UUID, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –§–ò–û
            message += f"\n–ú–µ–Ω–µ–¥–∂–µ—Ä: {manager_key[:8]}..."
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º send_message –≤–º–µ—Å—Ç–æ send_note, —Ç–∞–∫ –∫–∞–∫ note —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–µ –≤–∏–¥–Ω—ã –∫–ª–∏–µ–Ω—Ç—É
        await chatwoot_client.send_message(
            conversation_id=cons_id,
            content=message,
            message_type="outgoing"
        )
        
        # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —É–∂–µ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–æ –≤ check_and_log_notification
        
        logger.info(f"Sent redate message to Chatwoot for cons_id={cons_id}")
    except Exception as e:
        logger.warning(f"Failed to notify Chatwoot about redate (cons_id={cons_id}): {e}")


async def update_cl_consultation_date(
    cl_ref_key: str,
    new_date: Optional[datetime],
):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞—Ç—ã –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –≤ 1C:–¶–õ —á–µ—Ä–µ–∑ OData"""
    if not cl_ref_key or not new_date:
        return
    
    try:
        onec_client = OneCClient()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞—Ç—É –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –≤ –¶–õ
        await onec_client.update_consultation_odata(
            ref_key=cl_ref_key,
            start_date=new_date,
        )
        logger.debug(f"[pull_cons_redate_cl] Updated consultation date in CL for cl_ref_key={cl_ref_key[:20]}, new_date={new_date}")
    except Exception as e:
        logger.warning(f"Failed to update CL consultation date (cl_ref_key={cl_ref_key}): {e}")


async def process_batch(db: AsyncSession, batch: List[Dict[str, Any]]):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–∞—Ç—á –∑–∞–ø–∏—Å–µ–π –æ –ø–µ—Ä–µ–Ω–æ—Å–∞—Ö –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π.
    
    –í–ê–ñ–ù–û: –°–æ—Ä—Ç–∏—Ä—É–µ—Ç –∑–∞–ø–∏—Å–∏ –ø–æ cons_key –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è deadlocks –ø—Ä–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ.
    """
    rows: List[Dict[str, Any]] = []
    latest_period: Optional[datetime] = None
    for item in batch:
        cons_key = clean_uuid(item.get("–î–æ–∫—É–º–µ–Ω—Ç–û–±—Ä–∞—â–µ–Ω–∏—è_Key"))
        client_key = clean_uuid(item.get("–ê–±–æ–Ω–µ–Ω—Ç_Key"))
        manager_key = clean_uuid(item.get("–ú–µ–Ω–µ–¥–∂–µ—Ä_Key"))
        period_dt = clean_datetime(item.get("Period"))

        if not (cons_key and period_dt):
            continue

        row = {
            "cons_key": cons_key,
            "clients_key": client_key,
            "manager_key": manager_key,
            "period": period_dt,
            "old_date": clean_datetime(item.get("–°—Ç–∞—Ä–∞—è–î–∞—Ç–∞")),
            "new_date": clean_datetime(item.get("–ù–æ–≤–∞—è–î–∞—Ç–∞")),
        }
        rows.append(row)
        # –í–ê–ñ–ù–û: –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –æ–±–∞ datetime –∏–º–µ—é—Ç timezone –ø–µ—Ä–µ–¥ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ–º
        if latest_period is None:
            latest_period = period_dt
        elif period_dt:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ–±–∞ datetime –∫ UTC –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            if period_dt.tzinfo is None:
                period_dt = period_dt.replace(tzinfo=timezone.utc)
            if latest_period.tzinfo is None:
                latest_period = latest_period.replace(tzinfo=timezone.utc)
            if period_dt > latest_period:
                latest_period = period_dt

    if rows:
        # –í–ê–ñ–ù–û: –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ cons_key –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è deadlocks
        # –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –≤—Å–µ –ø—Ä–æ—Ü–µ—Å—Å—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –∑–∞–ø–∏—Å–∏ –≤ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–º –ø–æ—Ä—è–¥–∫–µ
        rows.sort(key=lambda r: r["cons_key"] or "")
        
        # –í—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å–∏ –∏ –ø–æ–ª—É—á–∞–µ–º –∫–ª—é—á–∏ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π
        new_keys = await upsert_redate_rows(db, rows)
        
        for row in rows:
            row_key = (row["cons_key"], row["clients_key"], row["manager_key"], row["period"])
            cons_key = row["cons_key"]
            old_date = row["old_date"]
            new_date = row["new_date"]
            manager_key = row["manager_key"]
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –≤ –ë–î
            await update_consultation_schedule(db, cons_key, new_date)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π
            # –í–ê–ñ–ù–û: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ notify_chatwoot_redate
            # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–ø—Ä–∞–≤–∫—É –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –¥–∞–∂–µ –µ—Å–ª–∏ –∑–∞–ø–∏—Å—å –≤ cons_redate –µ—â–µ –Ω–µ –≤ –ë–î
            if row_key in new_keys:
                # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Chatwoot –∏ –¶–õ
                result = await db.execute(
                    select(Consultation).where(Consultation.cl_ref_key == cons_key)
                )
                consultation = result.scalar_one_or_none()
                
                if consultation:
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ Chatwoot (–ø—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏)
                    if consultation.cons_id:
                        await notify_chatwoot_redate(
                            consultation.cons_id, old_date, new_date, manager_key, db=db
                        )
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞—Ç—É –≤ –¶–õ (–µ—Å–ª–∏ –µ—Å—Ç—å cl_ref_key)
                    if consultation.cl_ref_key:
                        await update_cl_consultation_date(consultation.cl_ref_key, new_date)
    
    return len(rows), latest_period


async def pull_cons_redate():
    etl_logger = ETLLogger("pull_cons_redate_cl", ENTITY)
    
    if not (ODATA_BASEURL and ODATA_USER and ODATA_PASSWORD):
        etl_logger.critical_error("ODATA config missing. Check ODATA_BASEURL_CL, ODATA_USER, ODATA_PASSWORD")
        sys.exit(1)

    etl_logger.start({
        "ODATA_BASEURL": ODATA_BASEURL,
        "ENTITY": ENTITY,
        "INITIAL_FROM_DATE": INITIAL_FROM_DATE,
        "PAGE_SIZE": PAGE_SIZE
    })

    auth = (ODATA_USER, ODATA_PASSWORD)
    # –í–ê–ñ–ù–û: –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –¥–ª—è ETL —Å–∫—Ä–∏–ø—Ç–∞
    engine = create_async_engine(
        DATABASE_URL,
        echo=False,
        pool_size=2,
        max_overflow=2,
        pool_pre_ping=True,
        pool_recycle=3600,
        pool_timeout=30
    )
    AsyncSessionLocal = async_sessionmaker(engine, expire_on_commit=False)

    try:
        async with AsyncSessionLocal() as db:
            last_sync = await get_last_sync_date(db)
            if last_sync:
                from_dt = last_sync - timedelta(hours=6)
                from_date = from_dt.strftime("%Y-%m-%dT%H:%M:%S")
                etl_logger.sync_info(last_sync, from_date, buffer_days=None)  # –ë—É—Ñ–µ—Ä –≤ —á–∞—Å–∞—Ö
            else:
                from_date = f"{INITIAL_FROM_DATE}T00:00:00"
                etl_logger.sync_info(None, from_date)

            skip = 0
            error_logs = 0
            last_period_processed: Optional[datetime] = last_sync

            while True:
                batch_num = skip // PAGE_SIZE + 1
                filter_part = f"Period ge datetime'{from_date}'"
                url = (
                    f"{ODATA_BASEURL}{ENTITY}?$format=json"
                    f"&$filter={quote(filter_part)}"
                    f"&$orderby=Period asc"
                    f"&$top={PAGE_SIZE}&$skip={skip}"
                )

                etl_logger.batch_start(batch_num, skip, PAGE_SIZE)

                try:
                    resp = http_get_with_backoff(url, auth)
                except Exception as exc:
                    etl_logger.batch_error(batch_num, exc, skip)
                    break

                batch = resp.json().get("value", [])
                if not batch:
                    break

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á —Å retry –¥–ª—è deadlock –æ—à–∏–±–æ–∫
                max_deadlock_retries = 3
                deadlock_retry_delay = 0.1  # –ù–∞—á–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
                processed = None
                latest_period = None
                
                for deadlock_attempt in range(1, max_deadlock_retries + 1):
                    try:
                        processed, latest_period = await process_batch(db, batch)
                        if latest_period:
                            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ–±–∞ datetime –∫ UTC –ø–µ—Ä–µ–¥ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ–º
                            if latest_period.tzinfo is None:
                                latest_period = latest_period.replace(tzinfo=timezone.utc)
                            if last_period_processed is None:
                                last_period_processed = latest_period
                            else:
                                if last_period_processed.tzinfo is None:
                                    last_period_processed = last_period_processed.replace(tzinfo=timezone.utc)
                                if latest_period > last_period_processed:
                                    last_period_processed = latest_period
                        
                        # –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–ª–∏, –≤—ã—Ö–æ–¥–∏–º –∏–∑ retry —Ü–∏–∫–ª–∞
                        break
                    except Exception as exc:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ deadlock –æ—à–∏–±–∫–æ–π
                        is_deadlock = False
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã deadlock –æ—à–∏–±–æ–∫
                        if isinstance(exc, OperationalError):
                            # SQLAlchemy –æ–±–æ—Ä–∞—á–∏–≤–∞–µ—Ç asyncpg –∏—Å–∫–ª—é—á–µ–Ω–∏—è –≤ OperationalError
                            orig_exc = getattr(exc, 'orig', None)
                            if isinstance(orig_exc, asyncpg.exceptions.DeadlockDetectedError):
                                is_deadlock = True
                        elif isinstance(exc, asyncpg.exceptions.DeadlockDetectedError):
                            # –ü—Ä—è–º–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ asyncpg (–º–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω–æ, –Ω–æ –≤–æ–∑–º–æ–∂–Ω–æ)
                            is_deadlock = True
                        elif "deadlock detected" in str(exc).lower():
                            # Fallback: –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Ç–µ–∫—Å—Ç—É –æ—à–∏–±–∫–∏
                            is_deadlock = True
                        
                        if is_deadlock and deadlock_attempt < max_deadlock_retries:
                            # Deadlock - –¥–µ–ª–∞–µ–º rollback –∏ retry —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π
                            await db.rollback()
                            wait_time = deadlock_retry_delay * (2 ** (deadlock_attempt - 1))
                            logger.warning(
                                f"[pull_cons_redate_cl] Deadlock detected in batch {batch_num} "
                                f"(attempt {deadlock_attempt}/{max_deadlock_retries}). "
                                f"Retrying in {wait_time:.2f}s..."
                            )
                            await asyncio.sleep(wait_time)
                            continue
                        else:
                            # –ù–µ deadlock –∏–ª–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã –ø–æ–ø—ã—Ç–∫–∏ - –ª–æ–≥–∏—Ä—É–µ–º –∏ –ø—Ä–µ—Ä—ã–≤–∞–µ–º
                            if error_logs < MAX_ERROR_LOGS:
                                etl_logger.batch_error(batch_num, exc, skip)
                            elif error_logs == MAX_ERROR_LOGS:
                                logger.warning("[pull_cons_redate_cl] Further redate processing errors suppressed")
                            error_logs += 1
                            await db.rollback()
                            break
                
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –±–∞—Ç—á –ø–æ—Å–ª–µ –≤—Å–µ—Ö retry, –ø—Ä–µ—Ä—ã–≤–∞–µ–º —Ü–∏–∫–ª
                if processed is None:
                    break

                await db.commit()

                # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ç—á–∞
                etl_logger.batch_progress(batch_num, len(batch), created=processed, updated=0, errors=0)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º sync_state –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞
                if last_period_processed:
                    try:
                        await save_sync_date(db, last_period_processed)
                        await db.commit()
                        etl_logger.sync_state_saved(last_period_processed, batch_num)
                    except Exception as sync_error:
                        logger.warning(f"[pull_cons_redate_cl] Failed to save sync state after batch: {sync_error}")

                if len(batch) < PAGE_SIZE:
                    break
                skip += PAGE_SIZE

            # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞—Ç—ã —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
            if last_period_processed:
                await save_sync_date(db, last_period_processed)
                await db.commit()
                etl_logger.sync_state_saved(last_period_processed)
            
            etl_logger.finish(success=True)
    except Exception as e:
        etl_logger.finish(success=False, error=e)
        sys.exit(1)
    finally:
        await engine.dispose()


if __name__ == "__main__":
    asyncio.run(ensure_support_objects())
    asyncio.run(pull_cons_redate())

